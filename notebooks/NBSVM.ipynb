{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /u/arsaikia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from Twitter import TwitterAccess\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "pd.options.display.max_colwidth = None\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from spellchecker import SpellChecker\n",
    "import random\n",
    "import numpy as np\n",
    "from multiprocessing import  Pool\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin # ???\n",
    "from sklearn.utils.validation import check_X_y, check_is_fitted # ???\n",
    "from scipy import sparse #???\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NbSvmClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, C=1.0, dual=False, n_jobs=1):\n",
    "        self.C = C\n",
    "        self.dual = dual\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def predict(self, x):\n",
    "        # Verify that model has been fit\n",
    "        check_is_fitted(self, ['_r', '_clf'])\n",
    "        return self._clf.predict(x.multiply(self._r))\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        # Verify that model has been fit\n",
    "        check_is_fitted(self, ['_r', '_clf'])\n",
    "        return self._clf.predict_proba(x.multiply(self._r))\n",
    "\n",
    "    def pr(self, x, y_i, y):\n",
    "        p = x[y==y_i].sum(0)\n",
    "        return (p+1) / ((y==y_i).sum()+1)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        # Check that X and y have correct shape\n",
    "#         y = y\n",
    "        x, y = check_X_y(x, y, accept_sparse=True)\n",
    "        self._r = sparse.csr_matrix(np.log(self.pr(x,1,y) / self.pr(x,0,y)))\n",
    "        x_nb = x.multiply(self._r)\n",
    "        self._clf = LogisticRegression(C=self.C, dual=self.dual, n_jobs=self.n_jobs, solver ='liblinear').fit(x_nb, y)\n",
    "        self.coef_ = self._clf.coef_\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_validate(X, y, min_df):\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "    tfv = TfidfVectorizer(tokenizer=nltk.casual_tokenize, min_df=min_df,  max_features=30000, \n",
    "                strip_accents='unicode', analyzer='word',ngram_range=(1,1),\n",
    "                use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "                stop_words = 'english')\n",
    "    X = tfv.fit_transform(X).tocsr()\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    print(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)\n",
    "\n",
    "    model = NbSvmClassifier(C=4, dual=True, n_jobs=1)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    preds_valid = model.predict(X_valid)\n",
    "    proba_valid = model.predict_proba(X_valid)[:,1]\n",
    "    preds_train = model.predict(X_train)\n",
    "    proba_train = model.predict_proba(X_train)[:,1]\n",
    "\n",
    "\n",
    "    print(classification_report(y_train, preds_train))\n",
    "    try:\n",
    "        print('AUC: ',  roc_auc_score(y_train, proba_train))\n",
    "    except:\n",
    "        print('AUC: ',  roc_auc_score(y_train, model.predict_proba(X_train), multi_class ='ovr'))\n",
    "        \n",
    "    print(classification_report(y_valid, preds_valid))\n",
    "    try:\n",
    "        print('AUC: ',  roc_auc_score(y_valid, proba_valid))\n",
    "    except:\n",
    "        print('AUC: ',  roc_auc_score(y_valid, model.predict_proba(X_valid), multi_class ='ovr'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X, y, X_test,y_test,min_df):\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "    tfv = TfidfVectorizer(tokenizer=nltk.casual_tokenize, min_df=min_df,  max_features=30000, \n",
    "                strip_accents='unicode', analyzer='word',ngram_range=(1,1),\n",
    "                use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "                stop_words = 'english')\n",
    "    X = tfv.fit_transform(X).tocsr()\n",
    "\n",
    "    model = NbSvmClassifier(C=4, dual=True, n_jobs=1)\n",
    "\n",
    "    model.fit(X, y)\n",
    "\n",
    "    y_test = le.transform(y_test)\n",
    "    X_test = tfv.transform(X_test).tocsr()\n",
    "\n",
    "    print(X_test.shape, y_test.shape)\n",
    "    preds_test = model.predict(X_test)\n",
    "    proba_test = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "    print(classification_report(y_test, preds_test))\n",
    "    try:\n",
    "        print('AUC: ',  roc_auc_score(y_test, proba_test))\n",
    "    except:\n",
    "        print('AUC: ',  roc_auc_score(y_test, model.predict_proba(X_test), multi_class ='ovr'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSED = './preprocessed/'\n",
    "\n",
    "olid = pd.read_csv(PREPROCESSED + 'olid.csv')\n",
    "olid_traina = olid[~pd.isna(olid['tweet_cleaned'])]\n",
    "olid_trainb = olid_traina[~pd.isna(olid_traina['subtask_b'])]\n",
    "olid_trainc = olid_traina[~pd.isna(olid_traina['subtask_c'])]\n",
    "\n",
    "\n",
    "olid_testa = pd.read_csv(PREPROCESSED + 'olid-levela.csv')\n",
    "olid_testa = olid_testa[~pd.isna(olid_testa['tweet_cleaned'])]\n",
    "\n",
    "olid_testb = pd.read_csv(PREPROCESSED + 'olid-levelb.csv')\n",
    "olid_testb = olid_testb[~pd.isna(olid_testb['tweet_cleaned'])]\n",
    "\n",
    "olid_testc = pd.read_csv(PREPROCESSED + 'olid-levelc.csv')\n",
    "olid_testc = olid_testc[~pd.isna(olid_testc['tweet_cleaned'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8870, 1084) (4369, 1084) (8870,) (4369,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86      5922\n",
      "           1       0.80      0.51      0.63      2948\n",
      "\n",
      "    accuracy                           0.80      8870\n",
      "   macro avg       0.80      0.73      0.74      8870\n",
      "weighted avg       0.80      0.80      0.78      8870\n",
      "\n",
      "AUC:  0.8442547096881807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.92      0.84      2917\n",
      "           1       0.73      0.45      0.56      1452\n",
      "\n",
      "    accuracy                           0.76      4369\n",
      "   macro avg       0.75      0.68      0.70      4369\n",
      "weighted avg       0.76      0.76      0.74      4369\n",
      "\n",
      "AUC:  0.7621498511150084\n",
      "(859, 1084) (859,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88       619\n",
      "           1       0.78      0.47      0.58       240\n",
      "\n",
      "    accuracy                           0.81       859\n",
      "   macro avg       0.80      0.71      0.73       859\n",
      "weighted avg       0.81      0.81      0.80       859\n",
      "\n",
      "AUC:  0.7697260366182015\n"
     ]
    }
   ],
   "source": [
    "train_validate(olid_traina['tweet_cleaned'], olid_traina['subtask_a'], 20)\n",
    "test(olid_traina['tweet_cleaned'], olid_traina['subtask_a'], olid_testa['tweet_cleaned'], olid_testa['subtask_a'], 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2948, 1718) (1452, 1718) (2948,) (1452,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      2599\n",
      "           1       0.89      0.21      0.33       349\n",
      "\n",
      "    accuracy                           0.90      2948\n",
      "   macro avg       0.90      0.60      0.64      2948\n",
      "weighted avg       0.90      0.90      0.88      2948\n",
      "\n",
      "AUC:  0.9274379279665642\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93      1277\n",
      "           1       0.34      0.07      0.11       175\n",
      "\n",
      "    accuracy                           0.87      1452\n",
      "   macro avg       0.61      0.53      0.52      1452\n",
      "weighted avg       0.82      0.87      0.83      1452\n",
      "\n",
      "AUC:  0.6219510012305627\n",
      "(240, 1718) (240,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94       213\n",
      "           1       0.50      0.11      0.18        27\n",
      "\n",
      "    accuracy                           0.89       240\n",
      "   macro avg       0.70      0.55      0.56       240\n",
      "weighted avg       0.85      0.89      0.85       240\n",
      "\n",
      "AUC:  0.743696748391584\n"
     ]
    }
   ],
   "source": [
    "train_validate(olid_trainb['tweet_cleaned'], olid_trainb['subtask_b'],5)\n",
    "test(olid_trainb['tweet_cleaned'], olid_trainb['subtask_b'], olid_testb['tweet_cleaned'], olid_testb['subtask_b'],5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2596, 1580) (1280, 1580) (2596,) (1280,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.71      0.75       735\n",
      "           1       0.80      0.95      0.87      1600\n",
      "           2       0.88      0.13      0.23       261\n",
      "\n",
      "    accuracy                           0.80      2596\n",
      "   macro avg       0.82      0.60      0.62      2596\n",
      "weighted avg       0.81      0.80      0.77      2596\n",
      "\n",
      "AUC:  0.9219482342654777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.47      0.50       339\n",
      "           1       0.72      0.87      0.79       807\n",
      "           2       0.20      0.01      0.03       134\n",
      "\n",
      "    accuracy                           0.67      1280\n",
      "   macro avg       0.48      0.45      0.44      1280\n",
      "weighted avg       0.62      0.67      0.63      1280\n",
      "\n",
      "AUC:  0.7012538330907798\n",
      "(213, 1580) (213,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.46      0.55        78\n",
      "           1       0.57      0.89      0.70       100\n",
      "           2       0.50      0.06      0.10        35\n",
      "\n",
      "    accuracy                           0.60       213\n",
      "   macro avg       0.58      0.47      0.45       213\n",
      "weighted avg       0.60      0.60      0.54       213\n",
      "\n",
      "AUC:  0.6803372431371724\n"
     ]
    }
   ],
   "source": [
    "train_validate(olid_trainc['tweet_cleaned'], olid_trainc['subtask_c'],5)\n",
    "test(olid_trainc['tweet_cleaned'], olid_trainc['subtask_c'], olid_testc['tweet_cleaned'], olid_testc['subtask_c'],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_lr_feats(features,row, top_n=25, pos = True):\n",
    "    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n",
    "    if pos == True:\n",
    "        topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    else:\n",
    "        topn_ids = np.argsort(row)[:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    return df.iloc[:,0].values, df.iloc[:,1].values\n",
    "\n",
    "\n",
    "fig,(ax1,ax2)=plt.subplots(2,1,figsize=(15,7))\n",
    "\n",
    "features = np.array(tfv.get_feature_names())\n",
    "x, y = top_lr_feats(features,  model.coef_[0],top_n = 20, pos = True)\n",
    "sns.barplot(x, y, ax = ax1)\n",
    "ax1.set_title('Class : Offensive tweets (OFF)')\n",
    "x, y = top_lr_feats(features, model.coef_[0], top_n = 20, pos = False)\n",
    "sns.barplot(x, y, ax = ax2)\n",
    "ax2.set_title('Class : Not offensive tweets  (NOT)')\n",
    "\n",
    "fig.text(0.5, 0.04, 'unigrams', ha='center')\n",
    "fig.text(0.05, 0.5, 'coeff', va='center',  rotation='vertical')\n",
    "fig.suptitle('Feature Importances', fontsize=16)\n",
    "# sns.barplot(features,model.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "      <th>tweet_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAGA #Trump2020 👊🇺🇸👊 URL</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>go home you’re drunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>97670</td>\n",
       "      <td>@USER Liberals are all Kookoo !!!</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "      <td>liberals are all kookoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52415</td>\n",
       "      <td>@USER was literally just talking about this lol all mass shootings like that have been set ups. it’s propaganda used to divide us on major issues like gun control and terrorism</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "      <td>was literally just talking about this lol all mass shootings like that have been set ups it’s propaganda used to divide us on major issues like gun control and terrorism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13384</td>\n",
       "      <td>@USER Canada doesn’t need another CUCK! We already have enough #LooneyLeft #Liberals f**king up our great country! #Qproofs #TrudeauMustGo</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>canada doesn’t need another cuck we already have enough   fking up our great country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>28414</td>\n",
       "      <td>@USER you are a lying corrupt traitor!!! Nobody wants to hear anymore of your lies!!! #DeepStateCorruption URL</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>you are a lying corrupt traitor nobody wants to hear anymore of your lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13212</th>\n",
       "      <td>93164</td>\n",
       "      <td>@USER @USER Everything else was ten years ago. \"  YOU ARE A LIAR, this is total BS propaganda from team Trump  his crimes were throughout the past decade, including up to 2016\"</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>everything else was ten years ago   you are a liar this is total bs propaganda from team trump  his crimes were throughout the past decade including up to 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13223</th>\n",
       "      <td>63482</td>\n",
       "      <td>@USER is advocating for conduct within bounds of Human Rights but can the terrorists can be categorized as Human? They kill people mostly innocent just like berserk wild beasts. Even wild beasts kill only when hungry. So I feel that the Indian Army who are doing greatly. URL</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "      <td>is advocating for conduct within bounds of human rights but can the terrorists can be categorized as human they kill people mostly innocent just like berserk wild beasts even wild beasts kill only when hungry so i feel that the indian army who are doing greatly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13227</th>\n",
       "      <td>87416</td>\n",
       "      <td>@USER @USER @USER @USER Liars like the Antifa twins you vigorously defend?</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>GRP</td>\n",
       "      <td>liars like the antifa twins you vigorously defend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13235</th>\n",
       "      <td>95338</td>\n",
       "      <td>@USER Sometimes I get strong vibes from people and this man’s vibe is tens of millions of murders - he is more dangerous than DT.</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "      <td>sometimes i get strong vibes from people and this man’s vibe is tens of millions of murders  he is more dangerous than dt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13237</th>\n",
       "      <td>82921</td>\n",
       "      <td>@USER And why report this garbage.  We don't give a crap.</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>OTH</td>\n",
       "      <td>and why report this garbage  we dont give a crap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3876 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  \\\n",
       "1      90194   \n",
       "5      97670   \n",
       "7      52415   \n",
       "9      13384   \n",
       "12     28414   \n",
       "...      ...   \n",
       "13212  93164   \n",
       "13223  63482   \n",
       "13227  87416   \n",
       "13235  95338   \n",
       "13237  82921   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                     tweet  \\\n",
       "1                                                                                                                                                                                                                      @USER @USER Go home you’re drunk!!! @USER #MAGA #Trump2020 👊🇺🇸👊 URL   \n",
       "5                                                                                                                                                                                                                                                        @USER Liberals are all Kookoo !!!   \n",
       "7                                                                                                         @USER was literally just talking about this lol all mass shootings like that have been set ups. it’s propaganda used to divide us on major issues like gun control and terrorism   \n",
       "9                                                                                                                                               @USER Canada doesn’t need another CUCK! We already have enough #LooneyLeft #Liberals f**king up our great country! #Qproofs #TrudeauMustGo   \n",
       "12                                                                                                                                                                          @USER you are a lying corrupt traitor!!! Nobody wants to hear anymore of your lies!!! #DeepStateCorruption URL   \n",
       "...                                                                                                                                                                                                                                                                                    ...   \n",
       "13212                                                                                                     @USER @USER Everything else was ten years ago. \"  YOU ARE A LIAR, this is total BS propaganda from team Trump  his crimes were throughout the past decade, including up to 2016\"   \n",
       "13223  @USER is advocating for conduct within bounds of Human Rights but can the terrorists can be categorized as Human? They kill people mostly innocent just like berserk wild beasts. Even wild beasts kill only when hungry. So I feel that the Indian Army who are doing greatly. URL   \n",
       "13227                                                                                                                                                                                                           @USER @USER @USER @USER Liars like the Antifa twins you vigorously defend?   \n",
       "13235                                                                                                                                                    @USER Sometimes I get strong vibes from people and this man’s vibe is tens of millions of murders - he is more dangerous than DT.   \n",
       "13237                                                                                                                                                                                                                            @USER And why report this garbage.  We don't give a crap.   \n",
       "\n",
       "      subtask_a subtask_b subtask_c  \\\n",
       "1           OFF       TIN       IND   \n",
       "5           OFF       TIN       OTH   \n",
       "7           OFF       TIN       GRP   \n",
       "9           OFF       TIN       IND   \n",
       "12          OFF       TIN       IND   \n",
       "...         ...       ...       ...   \n",
       "13212       OFF       TIN       IND   \n",
       "13223       OFF       TIN       GRP   \n",
       "13227       OFF       TIN       GRP   \n",
       "13235       OFF       TIN       IND   \n",
       "13237       OFF       TIN       OTH   \n",
       "\n",
       "                                                                                                                                                                                                                                                               tweet_cleaned  \n",
       "1                                                                                                                                                                                                                                                       go home you’re drunk  \n",
       "5                                                                                                                                                                                                                                                    liberals are all kookoo  \n",
       "7                                                                                                  was literally just talking about this lol all mass shootings like that have been set ups it’s propaganda used to divide us on major issues like gun control and terrorism  \n",
       "9                                                                                                                                                                                       canada doesn’t need another cuck we already have enough   fking up our great country  \n",
       "12                                                                                                                                                                                                 you are a lying corrupt traitor nobody wants to hear anymore of your lies  \n",
       "...                                                                                                                                                                                                                                                                      ...  \n",
       "13212                                                                                                        everything else was ten years ago   you are a liar this is total bs propaganda from team trump  his crimes were throughout the past decade including up to 2016  \n",
       "13223  is advocating for conduct within bounds of human rights but can the terrorists can be categorized as human they kill people mostly innocent just like berserk wild beasts even wild beasts kill only when hungry so i feel that the indian army who are doing greatly  \n",
       "13227                                                                                                                                                                                                                      liars like the antifa twins you vigorously defend  \n",
       "13235                                                                                                                                              sometimes i get strong vibes from people and this man’s vibe is tens of millions of murders  he is more dangerous than dt  \n",
       "13237                                                                                                                                                                                                                       and why report this garbage  we dont give a crap  \n",
       "\n",
       "[3876 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olid_trainc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hd",
   "language": "python",
   "name": "hd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
